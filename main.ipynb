{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models_dict = {\n",
    "    'MobileNetV3S': models.mobilenet_v3_small(weights=None),\n",
    "    'ShuffleNetV2': models.shufflenet_v2_x1_0(weights=None),\n",
    "    \"MobileNetV2\": models.mobilenet_v2(weights=None),\n",
    "    \"ResNet18\": models.resnet18(weights=None),\n",
    "    \"SqueezeNet\": models.squeezenet1_0(weights=None),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluation\n",
    "dataset_path = \"./dataset\"\n",
    "augment_data = True\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentations\n",
    "augmentations = {\n",
    "    \"brightness\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ColorJitter(brightness=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage(),\n",
    "        ]\n",
    "    ),\n",
    "    \"contrast\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ColorJitter(contrast=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage(),\n",
    "        ]\n",
    "    ),\n",
    "    \"saturation\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ColorJitter(saturation=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage(),\n",
    "        ]\n",
    "    ),\n",
    "    \"hue\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ColorJitter(hue=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage(),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1652875851.3497071: 100%|██████████| 144/144 [00:05<00:00, 26.67it/s]\n",
      "Processing 1652875901.3107166: 100%|██████████| 708/708 [00:26<00:00, 27.12it/s]\n",
      "Processing 1652876013.741493: 100%|██████████| 513/513 [00:18<00:00, 27.04it/s]\n",
      "Processing 1652876206.2541456: 100%|██████████| 828/828 [00:29<00:00, 27.83it/s]\n",
      "Processing 1652876485.8123376: 100%|██████████| 977/977 [00:35<00:00, 27.31it/s]\n",
      "Processing 1652959186.4507334: 100%|██████████| 805/805 [00:29<00:00, 26.92it/s]\n",
      "Processing 1652959347.972946: 100%|██████████| 612/612 [00:23<00:00, 26.36it/s]\n",
      "Processing 1653042695.4914637: 100%|██████████| 324/324 [00:11<00:00, 27.91it/s]\n",
      "Processing 1653042775.5213027: 100%|██████████| 382/382 [00:13<00:00, 28.06it/s]\n",
      "Processing 1653043202.5073502: 100%|██████████| 405/405 [00:14<00:00, 28.13it/s]\n",
      "Processing 1653043345.3415065: 100%|██████████| 288/288 [00:10<00:00, 27.51it/s]\n",
      "Processing 1653043428.8546412: 100%|██████████| 648/648 [00:24<00:00, 26.57it/s]\n"
     ]
    }
   ],
   "source": [
    "dirs = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "\n",
    "if augment_data:\n",
    "    for dir in dirs:\n",
    "        files = os.listdir(os.path.join(dataset_path, dir))\n",
    "\n",
    "        for file_name in tqdm(files, desc=f\"Processing {dir}\"):\n",
    "            file_path = os.path.join(dataset_path, dir, file_name)\n",
    "            photo_id = re.search(r\"\\d+\", file_name).group()\n",
    "\n",
    "            if file_name != f\"{photo_id}.jpg\":\n",
    "                continue\n",
    "\n",
    "            image = Image.open(file_path).convert(\"RGB\")\n",
    "\n",
    "            for name, augmentation in augmentations.items():\n",
    "                augmented_image = augmentation(image)\n",
    "                augmented_image = np.array(augmented_image)\n",
    "                augmented_image = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
    "                save_path = os.path.join(dataset_path, dir, f\"{photo_id}_{name}.jpg\")\n",
    "                cv2.imwrite(save_path, augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class JetBotDataset(Dataset):\n",
    "    def __init__(self, target_map, transform=None):\n",
    "        self.target_map = target_map\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, target = self.target_map[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        target = torch.tensor(target, dtype=torch.float32)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(path, dirs):\n",
    "    result = []\n",
    "    for dir in dirs:\n",
    "        labels = pd.read_csv(\n",
    "            f\"{path}/{dir}.csv\", header=None, index_col=0, names=[\"speed\", \"turn\"]\n",
    "        )\n",
    "        for file_name in os.listdir(os.path.join(path, dir)):\n",
    "            file_path = os.path.join(path, dir, file_name)\n",
    "            photo_id = int(re.search(r\"\\d+\", file_name).group())\n",
    "            if photo_id in labels.index:\n",
    "                target = labels.loc[photo_id]\n",
    "                result.append((file_path, (target[\"speed\"], target[\"turn\"])))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and transformation\n",
    "target_map = get_target(dataset_path, dirs)\n",
    "train_data, test_data = train_test_split(target_map, test_size=0.2, random_state=42)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = JetBotDataset(train_data, transform=transform)\n",
    "test_dataset = JetBotDataset(test_data, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify models for regression\n",
    "def modify_model(model, model_name):\n",
    "    if model_name == \"SqueezeNet\":\n",
    "        model.classifier[1] = nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "    elif model_name == \"MobileNetV2\":\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
    "    elif model_name == \"ResNet18\":\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "    elif model_name == \"MobileNetV3S\":\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, 2)\n",
    "    elif model_name == \"ShuffleNetV2\":\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\" Epoch {epoch}/{num_epochs - 1}\")\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            print(f\"  {phase} loss: {epoch_loss:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MobileNetV3S...\n",
      " Epoch 0/99\n"
     ]
    }
   ],
   "source": [
    "for model_name in models_dict:\n",
    "    model = modify_model(models_dict[model_name], model_name).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    dataloaders = {\"train\": train_loader, \"val\": test_loader}\n",
    "    print(f\"Training {model_name}...\")\n",
    "    trained_model = train_model(\n",
    "        model, dataloaders, criterion, optimizer, num_epochs=num_epochs\n",
    "    )\n",
    "    torch.save(trained_model.state_dict(), f\"{model_name}_model.pth\")\n",
    "    print(f\"{model_name} training complete.\")\n",
    "\n",
    "    # Export model to ONNX\n",
    "    dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "    torch.onnx.export(\n",
    "        trained_model,\n",
    "        dummy_input,\n",
    "        f\"./models/{model_name}.onnx\",\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "    )\n",
    "    print(f\"{model_name} exported as ONNX.\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "jetbot-dl-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
